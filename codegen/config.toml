# XChange DataObject Code Generation Configuration
#
# This file configures default settings for the codegen CLI.
# Command-line arguments override these settings.

[paths]
# Base directory containing IR folders (relative to project root)
ir_dir = "ir"

# Output directory for prompt packets (relative to project root)
# Packets are stored in: packets_dir/grouped/<ir>/
packets_dir = "prompt_packets"

# Output directory for generated C# code (relative to project root)
generated_dir = "generated"

[llm]
# Default LLM provider: "anthropic" or "openai"
provider = "openai"

# Default model (leave empty to use provider default)
# Anthropic default: claude-3-5-haiku-20241022
# OpenAI default: gpt-4o
#model = "gpt-5-nano-2025-08-07"
model = "gpt-5"
#model = "claude-3-5-haiku-20241022"

# Maximum tokens for LLM response
max_tokens = 4096

[prompting]
# Maximum fields per prompt page
max_fields_per_page = 6

# Schema filtering is configured in filters.toml
